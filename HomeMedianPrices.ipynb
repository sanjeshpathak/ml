{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mkKiHbL15Vi",
        "colab_type": "code",
        "outputId": "11b2ce2c-8387-412a-8512-ccf5aa05f797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn import preprocessing\n",
        "\n",
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/josephlee94/intuitive-deep-learning/master/Part%201%3A%20Predicting%20House%20Prices/housepricedata.csv')\n",
        "\n",
        "dataset = dataframe.values\n",
        "\n",
        "X = dataset[:,0:10]\n",
        "\n",
        "Y = dataset[:,10]\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Dense(128, activation='relu', input_shape=(10,)),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(X_train, Y_train, batch_size=32, epochs=100, validation_data=(X_val, Y_val))\n",
        "\n",
        "loss, acc = model.evaluate(X_test, Y_test)\n",
        "\n",
        "print(acc)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1022 samples, validate on 219 samples\n",
            "Epoch 1/100\n",
            "1022/1022 [==============================] - 0s 118us/sample - loss: 0.6735 - acc: 0.5108 - val_loss: 0.6683 - val_acc: 0.5662\n",
            "Epoch 2/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.6671 - acc: 0.5626 - val_loss: 0.6622 - val_acc: 0.6119\n",
            "Epoch 3/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.6605 - acc: 0.6301 - val_loss: 0.6560 - val_acc: 0.6621\n",
            "Epoch 4/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.6541 - acc: 0.6840 - val_loss: 0.6496 - val_acc: 0.7078\n",
            "Epoch 5/100\n",
            "1022/1022 [==============================] - 0s 58us/sample - loss: 0.6475 - acc: 0.7221 - val_loss: 0.6432 - val_acc: 0.7352\n",
            "Epoch 6/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.6409 - acc: 0.7417 - val_loss: 0.6370 - val_acc: 0.7397\n",
            "Epoch 7/100\n",
            "1022/1022 [==============================] - 0s 66us/sample - loss: 0.6343 - acc: 0.7436 - val_loss: 0.6308 - val_acc: 0.7580\n",
            "Epoch 8/100\n",
            "1022/1022 [==============================] - 0s 72us/sample - loss: 0.6276 - acc: 0.7701 - val_loss: 0.6243 - val_acc: 0.7671\n",
            "Epoch 9/100\n",
            "1022/1022 [==============================] - 0s 59us/sample - loss: 0.6204 - acc: 0.7750 - val_loss: 0.6176 - val_acc: 0.7854\n",
            "Epoch 10/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.6132 - acc: 0.7896 - val_loss: 0.6107 - val_acc: 0.7854\n",
            "Epoch 11/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.6057 - acc: 0.7916 - val_loss: 0.6038 - val_acc: 0.7991\n",
            "Epoch 12/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.5981 - acc: 0.8033 - val_loss: 0.5967 - val_acc: 0.8174\n",
            "Epoch 13/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.5902 - acc: 0.8131 - val_loss: 0.5892 - val_acc: 0.8174\n",
            "Epoch 14/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.5824 - acc: 0.8219 - val_loss: 0.5815 - val_acc: 0.8128\n",
            "Epoch 15/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.5743 - acc: 0.8121 - val_loss: 0.5742 - val_acc: 0.8356\n",
            "Epoch 16/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.5662 - acc: 0.8337 - val_loss: 0.5660 - val_acc: 0.8311\n",
            "Epoch 17/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.5580 - acc: 0.8297 - val_loss: 0.5582 - val_acc: 0.8356\n",
            "Epoch 18/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.5497 - acc: 0.8337 - val_loss: 0.5504 - val_acc: 0.8311\n",
            "Epoch 19/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.5413 - acc: 0.8376 - val_loss: 0.5423 - val_acc: 0.8311\n",
            "Epoch 20/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.5331 - acc: 0.8395 - val_loss: 0.5342 - val_acc: 0.8311\n",
            "Epoch 21/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.5247 - acc: 0.8386 - val_loss: 0.5265 - val_acc: 0.8402\n",
            "Epoch 22/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.5161 - acc: 0.8444 - val_loss: 0.5180 - val_acc: 0.8402\n",
            "Epoch 23/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.5079 - acc: 0.8356 - val_loss: 0.5107 - val_acc: 0.8539\n",
            "Epoch 24/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.4996 - acc: 0.8493 - val_loss: 0.5024 - val_acc: 0.8584\n",
            "Epoch 25/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.4914 - acc: 0.8434 - val_loss: 0.4951 - val_acc: 0.8447\n",
            "Epoch 26/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.4835 - acc: 0.8493 - val_loss: 0.4869 - val_acc: 0.8493\n",
            "Epoch 27/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.4754 - acc: 0.8493 - val_loss: 0.4792 - val_acc: 0.8539\n",
            "Epoch 28/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.4676 - acc: 0.8532 - val_loss: 0.4722 - val_acc: 0.8447\n",
            "Epoch 29/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.4600 - acc: 0.8532 - val_loss: 0.4658 - val_acc: 0.8447\n",
            "Epoch 30/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.4527 - acc: 0.8493 - val_loss: 0.4592 - val_acc: 0.8539\n",
            "Epoch 31/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.4459 - acc: 0.8513 - val_loss: 0.4514 - val_acc: 0.8447\n",
            "Epoch 32/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.4387 - acc: 0.8542 - val_loss: 0.4442 - val_acc: 0.8447\n",
            "Epoch 33/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.4323 - acc: 0.8562 - val_loss: 0.4400 - val_acc: 0.8539\n",
            "Epoch 34/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.4259 - acc: 0.8591 - val_loss: 0.4329 - val_acc: 0.8539\n",
            "Epoch 35/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.4199 - acc: 0.8562 - val_loss: 0.4279 - val_acc: 0.8584\n",
            "Epoch 36/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.4142 - acc: 0.8620 - val_loss: 0.4219 - val_acc: 0.8584\n",
            "Epoch 37/100\n",
            "1022/1022 [==============================] - 0s 58us/sample - loss: 0.4083 - acc: 0.8611 - val_loss: 0.4157 - val_acc: 0.8584\n",
            "Epoch 38/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.4029 - acc: 0.8562 - val_loss: 0.4118 - val_acc: 0.8539\n",
            "Epoch 39/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3980 - acc: 0.8581 - val_loss: 0.4063 - val_acc: 0.8584\n",
            "Epoch 40/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.3935 - acc: 0.8611 - val_loss: 0.4019 - val_acc: 0.8584\n",
            "Epoch 41/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.3886 - acc: 0.8601 - val_loss: 0.3963 - val_acc: 0.8584\n",
            "Epoch 42/100\n",
            "1022/1022 [==============================] - 0s 50us/sample - loss: 0.3842 - acc: 0.8601 - val_loss: 0.3928 - val_acc: 0.8539\n",
            "Epoch 43/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3799 - acc: 0.8630 - val_loss: 0.3897 - val_acc: 0.8447\n",
            "Epoch 44/100\n",
            "1022/1022 [==============================] - 0s 68us/sample - loss: 0.3762 - acc: 0.8601 - val_loss: 0.3851 - val_acc: 0.8447\n",
            "Epoch 45/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3724 - acc: 0.8669 - val_loss: 0.3815 - val_acc: 0.8447\n",
            "Epoch 46/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3690 - acc: 0.8650 - val_loss: 0.3785 - val_acc: 0.8539\n",
            "Epoch 47/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3648 - acc: 0.8620 - val_loss: 0.3784 - val_acc: 0.8493\n",
            "Epoch 48/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3624 - acc: 0.8650 - val_loss: 0.3725 - val_acc: 0.8447\n",
            "Epoch 49/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.3588 - acc: 0.8669 - val_loss: 0.3710 - val_acc: 0.8447\n",
            "Epoch 50/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3563 - acc: 0.8669 - val_loss: 0.3660 - val_acc: 0.8493\n",
            "Epoch 51/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3534 - acc: 0.8679 - val_loss: 0.3629 - val_acc: 0.8493\n",
            "Epoch 52/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3510 - acc: 0.8669 - val_loss: 0.3614 - val_acc: 0.8539\n",
            "Epoch 53/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3481 - acc: 0.8669 - val_loss: 0.3594 - val_acc: 0.8447\n",
            "Epoch 54/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3456 - acc: 0.8650 - val_loss: 0.3555 - val_acc: 0.8493\n",
            "Epoch 55/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3431 - acc: 0.8718 - val_loss: 0.3559 - val_acc: 0.8402\n",
            "Epoch 56/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3413 - acc: 0.8699 - val_loss: 0.3529 - val_acc: 0.8447\n",
            "Epoch 57/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3396 - acc: 0.8679 - val_loss: 0.3516 - val_acc: 0.8447\n",
            "Epoch 58/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3378 - acc: 0.8650 - val_loss: 0.3494 - val_acc: 0.8402\n",
            "Epoch 59/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.3357 - acc: 0.8699 - val_loss: 0.3468 - val_acc: 0.8447\n",
            "Epoch 60/100\n",
            "1022/1022 [==============================] - 0s 58us/sample - loss: 0.3338 - acc: 0.8728 - val_loss: 0.3450 - val_acc: 0.8447\n",
            "Epoch 61/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.3321 - acc: 0.8738 - val_loss: 0.3451 - val_acc: 0.8447\n",
            "Epoch 62/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3301 - acc: 0.8728 - val_loss: 0.3419 - val_acc: 0.8447\n",
            "Epoch 63/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3282 - acc: 0.8708 - val_loss: 0.3399 - val_acc: 0.8447\n",
            "Epoch 64/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.3270 - acc: 0.8718 - val_loss: 0.3390 - val_acc: 0.8447\n",
            "Epoch 65/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3247 - acc: 0.8748 - val_loss: 0.3383 - val_acc: 0.8447\n",
            "Epoch 66/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3236 - acc: 0.8728 - val_loss: 0.3354 - val_acc: 0.8447\n",
            "Epoch 67/100\n",
            "1022/1022 [==============================] - 0s 60us/sample - loss: 0.3224 - acc: 0.8748 - val_loss: 0.3385 - val_acc: 0.8493\n",
            "Epoch 68/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3214 - acc: 0.8728 - val_loss: 0.3352 - val_acc: 0.8493\n",
            "Epoch 69/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.3195 - acc: 0.8748 - val_loss: 0.3349 - val_acc: 0.8493\n",
            "Epoch 70/100\n",
            "1022/1022 [==============================] - 0s 59us/sample - loss: 0.3180 - acc: 0.8777 - val_loss: 0.3347 - val_acc: 0.8493\n",
            "Epoch 71/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3168 - acc: 0.8777 - val_loss: 0.3296 - val_acc: 0.8447\n",
            "Epoch 72/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.3156 - acc: 0.8748 - val_loss: 0.3311 - val_acc: 0.8493\n",
            "Epoch 73/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3141 - acc: 0.8816 - val_loss: 0.3264 - val_acc: 0.8493\n",
            "Epoch 74/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3136 - acc: 0.8777 - val_loss: 0.3297 - val_acc: 0.8447\n",
            "Epoch 75/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3114 - acc: 0.8767 - val_loss: 0.3250 - val_acc: 0.8447\n",
            "Epoch 76/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.3119 - acc: 0.8806 - val_loss: 0.3260 - val_acc: 0.8447\n",
            "Epoch 77/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3102 - acc: 0.8816 - val_loss: 0.3239 - val_acc: 0.8447\n",
            "Epoch 78/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.3095 - acc: 0.8777 - val_loss: 0.3251 - val_acc: 0.8447\n",
            "Epoch 79/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.3083 - acc: 0.8777 - val_loss: 0.3230 - val_acc: 0.8402\n",
            "Epoch 80/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3076 - acc: 0.8787 - val_loss: 0.3223 - val_acc: 0.8402\n",
            "Epoch 81/100\n",
            "1022/1022 [==============================] - 0s 50us/sample - loss: 0.3066 - acc: 0.8796 - val_loss: 0.3237 - val_acc: 0.8447\n",
            "Epoch 82/100\n",
            "1022/1022 [==============================] - 0s 57us/sample - loss: 0.3055 - acc: 0.8787 - val_loss: 0.3254 - val_acc: 0.8493\n",
            "Epoch 83/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3044 - acc: 0.8806 - val_loss: 0.3220 - val_acc: 0.8447\n",
            "Epoch 84/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3034 - acc: 0.8806 - val_loss: 0.3199 - val_acc: 0.8447\n",
            "Epoch 85/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.3026 - acc: 0.8787 - val_loss: 0.3194 - val_acc: 0.8447\n",
            "Epoch 86/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3025 - acc: 0.8796 - val_loss: 0.3205 - val_acc: 0.8493\n",
            "Epoch 87/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.3013 - acc: 0.8816 - val_loss: 0.3218 - val_acc: 0.8493\n",
            "Epoch 88/100\n",
            "1022/1022 [==============================] - 0s 50us/sample - loss: 0.2999 - acc: 0.8826 - val_loss: 0.3176 - val_acc: 0.8447\n",
            "Epoch 89/100\n",
            "1022/1022 [==============================] - 0s 59us/sample - loss: 0.2995 - acc: 0.8826 - val_loss: 0.3162 - val_acc: 0.8447\n",
            "Epoch 90/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.2989 - acc: 0.8826 - val_loss: 0.3181 - val_acc: 0.8493\n",
            "Epoch 91/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.2979 - acc: 0.8836 - val_loss: 0.3150 - val_acc: 0.8447\n",
            "Epoch 92/100\n",
            "1022/1022 [==============================] - 0s 58us/sample - loss: 0.2970 - acc: 0.8855 - val_loss: 0.3170 - val_acc: 0.8493\n",
            "Epoch 93/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.2964 - acc: 0.8836 - val_loss: 0.3179 - val_acc: 0.8539\n",
            "Epoch 94/100\n",
            "1022/1022 [==============================] - 0s 54us/sample - loss: 0.2958 - acc: 0.8855 - val_loss: 0.3164 - val_acc: 0.8493\n",
            "Epoch 95/100\n",
            "1022/1022 [==============================] - 0s 56us/sample - loss: 0.2949 - acc: 0.8836 - val_loss: 0.3156 - val_acc: 0.8493\n",
            "Epoch 96/100\n",
            "1022/1022 [==============================] - 0s 52us/sample - loss: 0.2938 - acc: 0.8836 - val_loss: 0.3123 - val_acc: 0.8402\n",
            "Epoch 97/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.2936 - acc: 0.8845 - val_loss: 0.3147 - val_acc: 0.8493\n",
            "Epoch 98/100\n",
            "1022/1022 [==============================] - 0s 53us/sample - loss: 0.2916 - acc: 0.8894 - val_loss: 0.3101 - val_acc: 0.8402\n",
            "Epoch 99/100\n",
            "1022/1022 [==============================] - 0s 51us/sample - loss: 0.2924 - acc: 0.8855 - val_loss: 0.3122 - val_acc: 0.8447\n",
            "Epoch 100/100\n",
            "1022/1022 [==============================] - 0s 55us/sample - loss: 0.2912 - acc: 0.8845 - val_loss: 0.3180 - val_acc: 0.8447\n",
            "219/219 [==============================] - 0s 45us/sample - loss: 0.2148 - acc: 0.9178\n",
            "0.91780823\n",
            "0.21483060241289878\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}